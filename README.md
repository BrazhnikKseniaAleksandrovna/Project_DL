# Распознавание ключевых голосвых команд
Проект, направленный на обнаружение однословных команд на основе набора данных Google Speech Commands. Мы извлекли из него всего 10 слов (их в наборе данных 35), чтобы сократить время обучения.

# О наборе данных
Google Speech Commands — это открытый датасет коротких голосовых команд на английском языке, разработанный Google для обучения моделей распознавания речи. Набор данных содержит 105 829 аудиофайлов продолжительностью в одну секунду. Каждый клип содержит одно из 35 различных слов (например: "yes", "no", "stop", "go", "left", "right" и т.д.), произнесенных тысячами разных субъектов.  

# Предобработка данных
Каждый аудиофайл проходит через строгий pipeline преобразований:
   - 



Метрику использовали базовую: accuracy



Попробов архитектуры, предложенные в статье, например:
  1. cnn-trad-fpool3: Два свёрточных слоя с пулингом по частоте.
  2. cnn-one-fstride4: Один свёрточный слой со страйдингом для экономии вычислений.



В Итоге мы составили свою архитектуру модели. 
Модель построена на основе сверточной нейросети (CNN) и используется для классификации коротких аудиофрагментов:

CNN-блок (self.cnn):

2 сверточных слоя с ядром 3×3 и ReLU-активацией;
2 слоя субдискретизации (MaxPooling);
работает с входами формата [batch, 1, mel, time].
GAP (Global Average Pooling) — nn.AdaptiveAvgPool2d((1, 1)) — приводит карту признаков к фиксированному размеру независимо от входа.

Полносвязный блок (self.fc):

слой Flatten;
линейный слой 16→64;
ReLU;
линейный слой 64→количество классов.
Метод forward(x):

добавляет канал (unsqueeze);
последовательно применяет все блоки.

Теперь расскажем об обработке: 

Мы ограничили количество классов для ускорения экспериментов, выбрав 10 основных команд:
- Основные команды: 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go'
- Дополнительно мы добавили класс 'unknown' для всех остальных команд, чтобы модель могла распознавать посторонние слова

Для балансировки данных мы:
- Сохранили все примеры выбранных классов
- Для класса 'unknown' взяли только 4% от общего количества примеров 
- Равномерно распредели примеры между разными словами в классе 'unknown'
на трейне, получили такой распределение:
down: 3134
go: 3106
left: 3037
no: 3130
off: 2970
on: 3086
right: 3019
stop: 3111
up: 2948
yes: 3228
unknown: 3375
Классы у нас хорошо расспределены, нет дисбаланса. 
  (если есть желание усложнить задачу, можно добавить forward, backward, follow, но мы не нашли применение этих команд в нашем приложении, а так же эти в этих классах меньше данных, чем в остальных, раза в 2)
А также 

а) Конвертация в моно-формат
- Все стереозаписи преобразуются в моно путем усреднения каналов
- Это уменьшает размерность данных без потери ключевой информации

б) Ресемплирование
- Все записи приводятся к единой частоте 16 кГц
- Используется билинейная интерполяция для сохранения качества

в) Нормализация длины
- Фиксированная длительность 1 секунда (16000 samples)
- Короткие записи дополняются нулями (zero-padding)
- Длинные записи обрезаются случайным образом

г) Преобразование в мел-спектрограмму
- Применяется преобразование Фурье с окном 1024 samples
- Используется 64 мел-фильтра для получения спектральных характеристик
- Шаг окна (hop_length) 256 samples обеспечивает хороший компромисс между детализацией и размером данных

д) Логарифмическое преобразование
- Амплитуды преобразуются в децибелы для лучшего восприятия моделью
- Проводится стандартная нормализация.

Для повышения устойчивости модели к реальным условиям мы использовали комплекс аугментаций, которые делают данные более разнообразными и приближенными к реальным записям. Основные преобразования включают добавление случайного шума, временной сдвиг и изменение громкости.  

Добавление шума имитирует фоновые помехи — мы генерировали гауссовский шум с амплитудой 0.003 и накладывали его на исходный сигнал. Это помогает модели научиться игнорировать слабые шумы, такие как фоновые разговоры или помехи микрофона, делая её более устойчивой к неидеальным условиям записи.  

Временной сдвиг позволяет имитировать естественные вариации в начале и конце произнесения команд. Мы случайным образом смещали аудиосигнал в пределах ±150 миллисекунд, обрезая излишки и дополняя нулями. Это важно, потому что в реальном времени команды могут начинаться не строго в один и тот же момент, и модель должна быть к этому готова.  

Изменение громкости помогает учесть различия в расстоянии до микрофона и громкости голоса. Мы умножаем сигнал на случайный коэффициент в диапазоне от 0.7 до 1.3, сохраняя разборчивость, но при этом заставляя модель адаптироваться к разной амплитуде звука.  

НО, к сожалению, приложение стало лучше работать с аугментацией, а так же видимо, наша задумака с добавлением класса unknown провалилась.
